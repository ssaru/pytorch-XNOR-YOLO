hyperparameter:
    # image ìˆ˜: 5717
    batch_size: &batch_size 4
    steps_per_epoch: &steps_per_epoch 1429
    lr: &lr 5e-4
    optimizer: &optimizer SGD
    momentum: &momentum 0.9
    epoch: &max_epochs 40000

project: &project XNOR_YOLO
experiments: &title 1.xnor-yolo(deterministic)

dataloader:
    type: DataLoader
    params:
        num_workers: 4
        batch_size: *batch_size

scheduler:
    type: OneCycleLR
    params:
        max_lr: 0.05
        steps_per_epoch: *steps_per_epoch
        epochs: *max_epochs
        pct_start: 0.2
        anneal_strategy: cos

optimizer:
    type: *optimizer
    params:
        lr: *lr
        momentum: *momentum

runner:
    type: TrainingContainer

    trainer:
        type: Trainer
        params:
            max_epochs: *max_epochs
            gpus: -1
            accelerator: dp
            fast_dev_run: false
            amp_level: "02"
            weights_summary: top
            reload_dataloaders_every_epoch: false
            resume_from_checkpoint: null
            benchmark: false
            deterministic: true
            num_sanity_val_steps: 5
            overfit_batches: 0.0
            precision: 32
            profiler: true

    earlystopping:
        type: EarlyStopping
        params:
            monitor: valid_loss
            mode: min
            patience: 30
            verbose: True

    experiments:
        name: *title
        project_name: *project
        output_dir: output/runs
#scheduler: # ExponentialLR in paper
# type: StepLR
# params:
#   step_size: 10
#   gamma: 0.8
#   last_epoch: -1
# type: MultiStepLR
# params:
#   milestones: [5, 10, 15, 25, 45, 50, 55, 60, 100, 200]
#   gamma: .5
#   last_epoch: -1
# type: ReduceLROnPlateau
# monitor: train_acc
# params:
#   mode: max
#   factor: 0.9
#   patience: 1
#   threshold: 0.0004
#   threshold_mode: rel
#   cooldown: 0
#   min_lr: 0
#   eps: 0.00000008
